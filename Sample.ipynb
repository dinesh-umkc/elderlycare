{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0            Did you feel that you forget something?   \n",
      "1        If so, is it happening more than one year?    \n",
      "2          Did you repeat some works again and again   \n",
      "3  How you manage your appointments? Did you keep...   \n",
      "4  How do you keep your house chores? Do you arra...   \n",
      "\n",
      "                              answer  Result  \n",
      "0    Sometimes I forget some matters       1  \n",
      "1  It is happening for several years       1  \n",
      "2        I am very good at gardening       0  \n",
      "3              I go to park everyday       0  \n",
      "4    I always keep in my arrangement       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "class Question:\n",
    "  questionId: str\n",
    "  questionText: str\n",
    "  answerText: str\n",
    "  def __init__(self, qId: str, qText: str,aText: str) -> None:\n",
    "        self.questionId = qId\n",
    "        self.questionText = qText\n",
    "        self.answerText = aText\n",
    "  \n",
    "\n",
    "questions=[]\n",
    "df = pd.read_csv(\"alzheimer_questionaire.csv\",encoding = 'cp1252')\n",
    "print(df.head())\n",
    "#df=df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dines\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "from transformers import BertForNextSentencePrediction, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model and a pretrained tokenizer\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-cased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy%: 72.91666666666666\n"
     ]
    }
   ],
   "source": [
    "matchCount=0\n",
    "for i, row in df.iterrows():\n",
    "  encoded = tokenizer.encode_plus(row['question'], text_pair=row['answer'], return_tensors='pt')\n",
    "  #print(encoded)\n",
    "  seq_relationship_logits = model(**encoded)[0]\n",
    "  probs = softmax(seq_relationship_logits, dim=1)\n",
    "  val= probs[0][0].item()\n",
    "  if(val>.7):\n",
    "    val=1\n",
    "  else:\n",
    "    val=0\n",
    "  if(val==row['Result']):\n",
    "    matchCount=matchCount+1\n",
    "accuracy= (matchCount/i)*100\n",
    "\n",
    "print('accuracy%:',accuracy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7f1f1ab4d88ae42e8502814ef307fb439607a8b564d8819a8f8e04b08de9098"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
